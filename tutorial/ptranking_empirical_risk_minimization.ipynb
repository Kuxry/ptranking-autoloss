{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##  The Empirical Risk Minimization Framework\n",
    "\n",
    "Let $\\mathcal{Q}$ and $\\mathcal{D}$ be the query space and the document space, respectively, we use $\\Phi:\\mathcal{Q}\\times\\mathcal{D}\\rightarrow\\mathcal{Z}=\\mathbb{R}^{d}$ to denote the mapping function for generating a feature vector for a query-document pair, where $\\mathcal{Z}$ represents the $d$-dimensional feature space. We use $\\mathcal{R}=\\mathbb{R}_{+}$ to denote the space of the ground-truth relevance scores each document receives. Thus for each query, we have a list of document feature vectors $X=(X_{1},...,X_{m})\\in\\mathcal{X}=\\mathcal{Z}^{m}$ and a corresponding list $Y=(Y_{1},...,Y_{m})\\in\\mathcal{Y}=\\mathcal{R}^{m}$ of ground-truth relevance scores. In practice, we get independently and identically distributed (i.i.d) samples $\\mathcal{S}=\\{(X_{i},Y_{i})\\}_{i=1}^{n}$\n",
    "from an unknown joint distribution $P(\\cdot,\\cdot)$ over $\\mathcal{X}\\times\\mathcal{Y}$. We use $f_{\\theta}:X\\rightarrow\\mathbb{R}_{+}^{m}$ parameterized by $\\theta\\in\\Theta$ to denote the real-valued ranking function, which assigns each document a score. The scores of the documents associated with the same query are used to rank the documents. We measure the loss of ranking documents for a query using $f_{\\theta}$ with the loss function $\\ell(f_{\\theta}(X),Y)$. The goal is to learn the optimal ranking function over a hypothesis space $\\mathcal{F}$ of ranking functions that can \\emph{minimize the expected risk} as defined below:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\min_{f_{\\theta}\\in\\mathcal{F}}\\Re(f_{\\theta})=\\min_{f_{\\theta}\\in\\mathcal{F}}\\int_{\\mathcal{X}\\times\\mathcal{Y}}\\ell(f_{\\theta}(X),Y)dP(X,Y)\n",
    "\\end{equation}\n",
    "\n",
    "Typically, $\\Re(f_{\\theta})$ is intractable to optimize directly and the joint distribution is unknown, we appeal to the \\emph{empirical risk minimization} to approximate the expected risk, which is defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\min_{f_{\\theta}\\in\\mathcal{F}}\\hat{\\Re}(f_{\\theta};\\mathcal{S})=\\min_{f_{\\theta}\\in\\mathcal{F}}\\frac{1}{n}\\sum_{i=1}^{n}\\ell(f_{\\theta}(X),Y)\n",
    "\\end{equation}\n",
    "\n",
    "Given the above optimization framework, one can design various ranking methods by deploying different loss functions to learn the parameters $\\theta$ based on the training documents. In the testing phase, the predicted ranking can be obtained efficiently by sorting the testing documents in descending order of their individual relevance scores $f_{\\theta}(X_{i})$.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}